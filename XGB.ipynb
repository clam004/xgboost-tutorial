{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "XGBoost models represent all problems as a regression predictive modeling problem that takes numerical values as input. Your data must be prepared into the expected format:\n",
    "\n",
    "- encode string output variables for classification.\n",
    "- prepare categorical input variables (ie one hot encoding)\n",
    "- handle missing data with XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Case: numeric inputs with categorical outputs\n",
    "\n",
    "meaning of input numbers in the iris dataset\n",
    "\n",
    "   1. sepal length in cm\n",
    "   2. sepal width in cm\n",
    "   3. petal length in cm\n",
    "   4. petal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import xgboost\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# load data from http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data \n",
    "data = pandas.read_csv('../data/iris.data', header=None)\n",
    "print(type(data))\n",
    "dataset = data.values # convert pandas dataframe to <class 'numpy.ndarray'>\n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "X = dataset[:,0:4]\n",
    "Y = dataset[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.0 2.0 3.5 1.0]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.9 3.2 5.7 2.3]]\n",
      "['Iris-setosa' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# print every 30th data point\n",
    "print(type(X), X.shape)\n",
    "print(X[::30])\n",
    "print(Y[::30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "print(label_encoded_y[::30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling new unseen categories\n",
    "\n",
    "If you use this label_encoder to convert categories to integer labels for the input to the\n",
    "model, if at test time you encounter a category that is not seen in the training set, the label_encoder can crash, in the future, you may need to custom design a 2 way dictionary\n",
    "that can handle the mapping of number:category that handles new unseen categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, \n",
    "                                                                    label_encoded_y, \n",
    "                                                                    test_size=test_size, \n",
    "                                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method=None, validate_parameters=False, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 2, 2, 1, 2, 2, 0, 2, 0]\n",
      "Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "print(predictions[::5])\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical inputs to Categorical ouputs\n",
    "\n",
    "input features of Breast Cancer Data Set\n",
    "\n",
    "1. Class: no-recurrence-events, recurrence-events\n",
    "2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.\n",
    "3. menopause: lt40, ge40, premeno.\n",
    "4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59\n",
    "5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39\n",
    "6. node-caps: yes, no.\n",
    "7. deg-malig: 1, 2, 3.\n",
    "8. breast: left, right.\n",
    "9. breast-quad: left-up, left-low, right-up,\tright-low, central.\n",
    "10. irradiat:\tyes, no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (286, 9)\n",
      "['no-recurrence-events' '30-39' 'premeno' '30-34' '0-2' 'no' 3 'left'\n",
      " 'left_low']\n",
      "['no-recurrence-events' '30-39' 'premeno' '30-34' '0-2' 'no' '3' 'left'\n",
      " 'left_low']\n",
      "['no' 'no' 'no' 'no' 'no' 'no']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = pandas.read_csv('../data/breast-cancer.data', header=None)\n",
    "dataset = data.values\n",
    "\n",
    "# split data into X and y\n",
    "X = dataset[:,0:9]\n",
    "Y = dataset[:,9]\n",
    "\n",
    "print(type(X), X.shape)\n",
    "print(X[0])\n",
    "X = X.astype(str) # deg-malig: int -> str\n",
    "\n",
    "\n",
    "print(X[0])\n",
    "print(Y[::50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost may assume that encoded integer values for each input variable have an ordinal relationship. For example that ‘left-up’ encoded as 0 and ‘left-low’ encoded as 1 for the breast-quad variable have a meaningful relationship as integers. In this case, this assumption is untrue.\n",
    "\n",
    "Instead, we must map these integer values onto new binary variables, one new variable for each categorical value.\n",
    "\n",
    "left-up, left-low, right-up, right-low, central ->\n",
    "\n",
    "1,0,0,0,0\n",
    "\n",
    "0,1,0,0,0\n",
    "\n",
    "0,0,1,0,0\n",
    "\n",
    "0,0,0,1,0\n",
    "\n",
    "0,0,0,0,1\n",
    "\n",
    "using the OneHotEncoder class in scikit-learn\n",
    "\n",
    "We can one hot encode each feature after we have label encoded it. First we must transform the feature array into a 2-dimensional NumPy array where each integer value is a feature vector with a length 1. We can then create the OneHotEncoder and encode the feature array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no-recurrence-events', 'recurrence-events'}\n",
      "{0, 1} (286,)\n",
      "[[0]\n",
      " [0]] (286, 1)\n",
      "[[1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# what are all the unique categories of the first feature?\n",
    "print(set(X[:,0]))\n",
    "label_encoder = LabelEncoder()\n",
    "feature = label_encoder.fit_transform(X[:,0])\n",
    "# they have now be encoded ordinally, but they are not ordinal\n",
    "print(set(feature), feature.shape)\n",
    "feature = feature.reshape(X.shape[0], 1) # add dimension: (286,) -> (286, 1) \n",
    "print(feature[:2], feature.shape)\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "feature = onehot_encoder.fit_transform(feature)\n",
    "print(feature[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: :  (286, 43)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoded_x = None\n",
    "for i in range(0, X.shape[1]):\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\tfeature = label_encoder.fit_transform(X[:,i])\n",
    "\tfeature = feature.reshape(X.shape[0], 1)\n",
    "\tonehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\tfeature = onehot_encoder.fit_transform(feature)\n",
    "\tif encoded_x is None:\n",
    "\t\tencoded_x = feature\n",
    "\telse:\n",
    "\t\tencoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
    "        \n",
    "print(\"X shape: : \", encoded_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_x[::90] # The input consists of each features one hot encoding concatenated together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(encoded_x, \n",
    "                                                    label_encoded_y, \n",
    "                                                    test_size=test_size, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "              validate_parameters=False, verbosity=None)\n",
      "Accuracy: 71.58%\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
